{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 영상입력수치예측(CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 0. 사용할 패키지 불러오기\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "width = 16\n",
    "height = 16\n",
    "\n",
    "def generate_dataset(samples):\n",
    "\n",
    "    ds_x = []\n",
    "    ds_y = []\n",
    "    \n",
    "    for it in range(samples):\n",
    "        \n",
    "        num_pt = np.random.randint(0, width * height)\n",
    "        img = generate_image(num_pt)\n",
    "        \n",
    "        ds_y.append(num_pt)\n",
    "        ds_x.append(img)\n",
    "    \n",
    "    return np.array(ds_x), np.array(ds_y).reshape(samples, 1)\n",
    "    \n",
    "def generate_image(points):\n",
    "    \n",
    "    img = np.zeros((width, height))\n",
    "    pts = np.random.random((points, 2))\n",
    "    \n",
    "    for ipt in pts:\n",
    "        img[int(ipt[0] * width), int(ipt[1] * height)] = 1\n",
    "    \n",
    "    return img.reshape(width, height, 1)\n",
    "\n",
    "# 1. 데이터셋 생성하기\n",
    "x_train, y_train = generate_dataset(1500)\n",
    "x_val, y_val = generate_dataset(300)\n",
    "x_test, y_test = generate_dataset(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 12767.5783 - val_loss: 1787.5796\n",
      "Epoch 2/1000\n",
      "1500/1500 [==============================] - 0s 114us/step - loss: 1363.6999 - val_loss: 1198.5547\n",
      "Epoch 3/1000\n",
      "1500/1500 [==============================] - 0s 115us/step - loss: 987.9475 - val_loss: 924.8146\n",
      "Epoch 4/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 704.5640 - val_loss: 601.2845\n",
      "Epoch 5/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 434.6757 - val_loss: 374.2312\n",
      "Epoch 6/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 312.6382 - val_loss: 320.2744\n",
      "Epoch 7/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 277.2581 - val_loss: 290.0927\n",
      "Epoch 8/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 261.4200 - val_loss: 277.0959\n",
      "Epoch 9/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 248.7233 - val_loss: 278.8373\n",
      "Epoch 10/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 247.1514 - val_loss: 265.3676\n",
      "Epoch 11/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 244.9410 - val_loss: 260.8319\n",
      "Epoch 12/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 236.1862 - val_loss: 259.2940\n",
      "Epoch 13/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 234.1801 - val_loss: 251.8547\n",
      "Epoch 14/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 239.5424 - val_loss: 247.7123\n",
      "Epoch 15/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 228.6566 - val_loss: 264.9808\n",
      "Epoch 16/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 230.1590 - val_loss: 246.4281\n",
      "Epoch 17/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 238.7603 - val_loss: 243.0067\n",
      "Epoch 18/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 219.3961 - val_loss: 241.5958\n",
      "Epoch 19/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 203.9797 - val_loss: 225.7667\n",
      "Epoch 20/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 200.2122 - val_loss: 222.8446\n",
      "Epoch 21/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 197.6331 - val_loss: 205.8323\n",
      "Epoch 22/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 191.4575 - val_loss: 239.5312\n",
      "Epoch 23/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 194.3091 - val_loss: 197.9948\n",
      "Epoch 24/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 173.6231 - val_loss: 202.1357\n",
      "Epoch 25/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 179.3808 - val_loss: 191.7974\n",
      "Epoch 26/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 168.8266 - val_loss: 197.7893\n",
      "Epoch 27/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 175.9148 - val_loss: 198.8748\n",
      "Epoch 28/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 168.9714 - val_loss: 189.9506\n",
      "Epoch 29/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 161.4879 - val_loss: 195.4118\n",
      "Epoch 30/1000\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 165.7300 - val_loss: 196.8144\n",
      "Epoch 31/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 158.6676 - val_loss: 181.8050\n",
      "Epoch 32/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 156.5881 - val_loss: 180.4159\n",
      "Epoch 33/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 155.2139 - val_loss: 222.1324\n",
      "Epoch 34/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 166.1589 - val_loss: 189.7610\n",
      "Epoch 35/1000\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 152.6198 - val_loss: 179.6025\n",
      "Epoch 36/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 147.8999 - val_loss: 184.9215\n",
      "Epoch 37/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 149.9580 - val_loss: 178.2051\n",
      "Epoch 38/1000\n",
      "1500/1500 [==============================] - 0s 116us/step - loss: 151.7371 - val_loss: 179.7815\n",
      "Epoch 39/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 156.7214 - val_loss: 171.9363\n",
      "Epoch 40/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 136.9825 - val_loss: 176.2862\n",
      "Epoch 41/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 141.4307 - val_loss: 169.1334\n",
      "Epoch 42/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 142.6731 - val_loss: 255.0351\n",
      "Epoch 43/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 147.6904 - val_loss: 171.6592\n",
      "Epoch 44/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 137.0347 - val_loss: 166.6327\n",
      "Epoch 45/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 129.6258 - val_loss: 166.2505\n",
      "Epoch 46/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 138.8157 - val_loss: 193.4891\n",
      "Epoch 47/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 135.6061 - val_loss: 169.6474\n",
      "Epoch 48/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 123.1855 - val_loss: 164.4710\n",
      "Epoch 49/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 135.1201 - val_loss: 191.5976\n",
      "Epoch 50/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 129.3722 - val_loss: 171.3445\n",
      "Epoch 51/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 122.2842 - val_loss: 173.4639\n",
      "Epoch 52/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 119.9584 - val_loss: 162.4661\n",
      "Epoch 53/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 124.9711 - val_loss: 163.2586\n",
      "Epoch 54/1000\n",
      "1500/1500 [==============================] - 0s 107us/step - loss: 120.1452 - val_loss: 163.4620\n",
      "Epoch 55/1000\n",
      "1500/1500 [==============================] - 0s 110us/step - loss: 120.1158 - val_loss: 165.9962\n",
      "Epoch 56/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 125.6134 - val_loss: 180.1010\n",
      "Epoch 57/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 115.8862 - val_loss: 162.0427\n",
      "Epoch 58/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 115.2716 - val_loss: 169.6896\n",
      "Epoch 59/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 114.0709 - val_loss: 175.8678\n",
      "Epoch 60/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 110.9589 - val_loss: 161.0194\n",
      "Epoch 61/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 112.5265 - val_loss: 164.7385\n",
      "Epoch 62/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 107.1418 - val_loss: 164.9010\n",
      "Epoch 63/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 104.8501 - val_loss: 165.0496\n",
      "Epoch 64/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 111.0128 - val_loss: 162.7377\n",
      "Epoch 65/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 102.8131 - val_loss: 162.1793\n",
      "Epoch 66/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 104.0641 - val_loss: 165.1364\n",
      "Epoch 67/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 98.3001 - val_loss: 169.5930\n",
      "Epoch 68/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 101.0031 - val_loss: 163.3683\n",
      "Epoch 69/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 99.0612 - val_loss: 159.9652\n",
      "Epoch 70/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 103.1599 - val_loss: 159.3591\n",
      "Epoch 71/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 98.0229 - val_loss: 158.9559\n",
      "Epoch 72/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 103.9118 - val_loss: 164.0381\n",
      "Epoch 73/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 96.8001 - val_loss: 165.7356\n",
      "Epoch 74/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 95.3406 - val_loss: 162.1451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 98.2318 - val_loss: 160.7824\n",
      "Epoch 76/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 97.5574 - val_loss: 169.7343\n",
      "Epoch 77/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 90.9533 - val_loss: 159.7292\n",
      "Epoch 78/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 86.1451 - val_loss: 163.9929\n",
      "Epoch 79/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 91.0568 - val_loss: 160.0691\n",
      "Epoch 80/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 84.6052 - val_loss: 169.2701\n",
      "Epoch 81/1000\n",
      "1500/1500 [==============================] - 0s 117us/step - loss: 83.0640 - val_loss: 183.2176\n",
      "Epoch 82/1000\n",
      "1500/1500 [==============================] - 0s 118us/step - loss: 89.0231 - val_loss: 159.9686\n",
      "Epoch 83/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 88.2111 - val_loss: 183.5498\n",
      "Epoch 84/1000\n",
      "1500/1500 [==============================] - 0s 119us/step - loss: 83.3522 - val_loss: 178.6699\n",
      "Epoch 85/1000\n",
      "1500/1500 [==============================] - 0s 117us/step - loss: 93.5042 - val_loss: 161.3501\n",
      "Epoch 86/1000\n",
      "1500/1500 [==============================] - 0s 117us/step - loss: 76.6013 - val_loss: 172.4661\n",
      "Epoch 87/1000\n",
      "1500/1500 [==============================] - 0s 117us/step - loss: 78.4687 - val_loss: 170.0014\n",
      "Epoch 88/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 77.6581 - val_loss: 167.8483\n",
      "Epoch 89/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 77.6717 - val_loss: 175.1289\n",
      "Epoch 90/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 79.5136 - val_loss: 164.9117\n",
      "Epoch 91/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 75.5530 - val_loss: 169.1218\n",
      "Epoch 92/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 71.9087 - val_loss: 163.4099\n",
      "Epoch 93/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 90.3577 - val_loss: 166.5309\n",
      "Epoch 94/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 72.0658 - val_loss: 177.9786\n",
      "Epoch 95/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 70.2753 - val_loss: 163.8818\n",
      "Epoch 96/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 66.4979 - val_loss: 168.0422\n",
      "Epoch 97/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 64.7339 - val_loss: 165.9002\n",
      "Epoch 98/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 75.9554 - val_loss: 201.4203\n",
      "Epoch 99/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 65.3253 - val_loss: 164.3550\n",
      "Epoch 100/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 64.3335 - val_loss: 164.2001\n",
      "Epoch 101/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 64.9981 - val_loss: 163.9388\n",
      "Epoch 102/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 62.9812 - val_loss: 166.2931\n",
      "Epoch 103/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 78.0758 - val_loss: 163.6324\n",
      "Epoch 104/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 58.8963 - val_loss: 172.5673\n",
      "Epoch 105/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 64.6016 - val_loss: 173.4375\n",
      "Epoch 106/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 57.8243 - val_loss: 165.1588\n",
      "Epoch 107/1000\n",
      "1500/1500 [==============================] - 0s 77us/step - loss: 62.1404 - val_loss: 170.5269\n",
      "Epoch 108/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 63.9401 - val_loss: 165.7538\n",
      "Epoch 109/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 60.3525 - val_loss: 182.8154\n",
      "Epoch 110/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 56.0475 - val_loss: 167.5330\n",
      "Epoch 111/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 51.0078 - val_loss: 166.5243\n",
      "Epoch 112/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 53.1473 - val_loss: 167.2948\n",
      "Epoch 113/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 57.2578 - val_loss: 178.4140\n",
      "Epoch 114/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 55.9894 - val_loss: 170.1256\n",
      "Epoch 115/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 49.1039 - val_loss: 167.0095\n",
      "Epoch 116/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 51.8835 - val_loss: 182.5078\n",
      "Epoch 117/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 50.1482 - val_loss: 183.1760\n",
      "Epoch 118/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 50.8278 - val_loss: 170.8254\n",
      "Epoch 119/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 46.0746 - val_loss: 168.9245\n",
      "Epoch 120/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 54.7325 - val_loss: 189.2801\n",
      "Epoch 121/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 50.2291 - val_loss: 169.1564\n",
      "Epoch 122/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 43.7089 - val_loss: 171.9206\n",
      "Epoch 123/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 46.7791 - val_loss: 175.0484\n",
      "Epoch 124/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 41.7473 - val_loss: 196.4502\n",
      "Epoch 125/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 43.8650 - val_loss: 171.6866\n",
      "Epoch 126/1000\n",
      "1500/1500 [==============================] - 0s 162us/step - loss: 45.6300 - val_loss: 167.8886\n",
      "Epoch 127/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 43.6276 - val_loss: 178.7918\n",
      "Epoch 128/1000\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 39.7666 - val_loss: 170.6385\n",
      "Epoch 129/1000\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 36.8317 - val_loss: 171.4145\n",
      "Epoch 130/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 39.7284 - val_loss: 171.7500\n",
      "Epoch 131/1000\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 37.6336 - val_loss: 171.0175\n",
      "Epoch 132/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 37.8089 - val_loss: 170.2268\n",
      "Epoch 133/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 33.6644 - val_loss: 175.7573\n",
      "Epoch 134/1000\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 33.5262 - val_loss: 178.9741\n",
      "Epoch 135/1000\n",
      "1500/1500 [==============================] - 0s 146us/step - loss: 37.4597 - val_loss: 171.6372\n",
      "Epoch 136/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 31.7113 - val_loss: 174.6209\n",
      "Epoch 137/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 33.4901 - val_loss: 174.7507\n",
      "Epoch 138/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 29.1630 - val_loss: 176.8182\n",
      "Epoch 139/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 31.5396 - val_loss: 178.0958\n",
      "Epoch 140/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 33.4910 - val_loss: 173.6023\n",
      "Epoch 141/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 31.5871 - val_loss: 177.8498\n",
      "Epoch 142/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 26.7204 - val_loss: 178.1766\n",
      "Epoch 143/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 26.3568 - val_loss: 178.3213\n",
      "Epoch 144/1000\n",
      "1500/1500 [==============================] - 0s 118us/step - loss: 26.3608 - val_loss: 177.8954\n",
      "Epoch 145/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 33.2120 - val_loss: 175.8995\n",
      "Epoch 146/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 26.7037 - val_loss: 177.8798\n",
      "Epoch 147/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 29.2833 - val_loss: 177.5359\n",
      "Epoch 148/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 22.9075 - val_loss: 180.7831\n",
      "Epoch 149/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 123us/step - loss: 23.4943 - val_loss: 178.8504\n",
      "Epoch 150/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 23.3395 - val_loss: 184.3563\n",
      "Epoch 151/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 25.1018 - val_loss: 185.7906\n",
      "Epoch 152/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 21.2616 - val_loss: 187.9222\n",
      "Epoch 153/1000\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 21.1908 - val_loss: 191.2554\n",
      "Epoch 154/1000\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 21.5529 - val_loss: 182.5197\n",
      "Epoch 155/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 26.7415 - val_loss: 189.4999\n",
      "Epoch 156/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 19.7853 - val_loss: 185.3562\n",
      "Epoch 157/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 16.6179 - val_loss: 183.1710\n",
      "Epoch 158/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 20.6475 - val_loss: 188.8776\n",
      "Epoch 159/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 18.0205 - val_loss: 190.1074\n",
      "Epoch 160/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 16.4721 - val_loss: 183.6353\n",
      "Epoch 161/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 16.6924 - val_loss: 190.9821\n",
      "Epoch 162/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 16.0661 - val_loss: 187.7698\n",
      "Epoch 163/1000\n",
      "1500/1500 [==============================] - 0s 114us/step - loss: 17.0190 - val_loss: 193.2425\n",
      "Epoch 164/1000\n",
      "1500/1500 [==============================] - 0s 119us/step - loss: 15.1927 - val_loss: 188.1104\n",
      "Epoch 165/1000\n",
      "1500/1500 [==============================] - 0s 115us/step - loss: 13.1416 - val_loss: 190.3388\n",
      "Epoch 166/1000\n",
      "1500/1500 [==============================] - 0s 117us/step - loss: 13.2523 - val_loss: 188.4666\n",
      "Epoch 167/1000\n",
      "1500/1500 [==============================] - 0s 111us/step - loss: 13.2531 - val_loss: 189.7995\n",
      "Epoch 168/1000\n",
      "1500/1500 [==============================] - 0s 117us/step - loss: 13.2641 - val_loss: 190.1716\n",
      "Epoch 169/1000\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 14.4521 - val_loss: 193.0151\n",
      "Epoch 170/1000\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 14.7984 - val_loss: 189.4922\n",
      "Epoch 171/1000\n",
      "1500/1500 [==============================] - 0s 146us/step - loss: 11.1319 - val_loss: 190.7943\n",
      "Epoch 172/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 10.6868 - val_loss: 192.4067\n",
      "Epoch 173/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 11.0582 - val_loss: 197.8571\n",
      "Epoch 174/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 12.7520 - val_loss: 192.8284\n",
      "Epoch 175/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 10.0373 - val_loss: 193.0016\n",
      "Epoch 176/1000\n",
      "1500/1500 [==============================] - 0s 118us/step - loss: 11.8104 - val_loss: 194.8462\n",
      "Epoch 177/1000\n",
      "1500/1500 [==============================] - 0s 117us/step - loss: 9.6442 - val_loss: 193.1708\n",
      "Epoch 178/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 16.5606 - val_loss: 197.0877\n",
      "Epoch 179/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 8.5362 - val_loss: 197.2319\n",
      "Epoch 180/1000\n",
      "1500/1500 [==============================] - 0s 117us/step - loss: 8.1076 - val_loss: 197.5897\n",
      "Epoch 181/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 9.9669 - val_loss: 197.6807\n",
      "Epoch 182/1000\n",
      "1500/1500 [==============================] - 0s 119us/step - loss: 9.0959 - val_loss: 197.8854\n",
      "Epoch 183/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 7.9865 - val_loss: 197.4096\n",
      "Epoch 184/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 8.0698 - val_loss: 201.1696\n",
      "Epoch 185/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 7.7119 - val_loss: 196.8503\n",
      "Epoch 186/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 7.1419 - val_loss: 198.9482\n",
      "Epoch 187/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 6.5853 - val_loss: 198.3433\n",
      "Epoch 188/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 5.6680 - val_loss: 201.4390\n",
      "Epoch 189/1000\n",
      "1500/1500 [==============================] - 0s 161us/step - loss: 6.5568 - val_loss: 208.2713\n",
      "Epoch 190/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 11.0687 - val_loss: 202.9657\n",
      "Epoch 191/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 7.0646 - val_loss: 199.2525\n",
      "Epoch 192/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 5.9377 - val_loss: 199.2133\n",
      "Epoch 193/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 7.0388 - val_loss: 204.9726\n",
      "Epoch 194/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 5.6605 - val_loss: 200.9406\n",
      "Epoch 195/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 4.8836 - val_loss: 201.2591\n",
      "Epoch 196/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 4.6543 - val_loss: 203.3047\n",
      "Epoch 197/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 5.2340 - val_loss: 201.0991\n",
      "Epoch 198/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 4.0143 - val_loss: 202.0097\n",
      "Epoch 199/1000\n",
      "1500/1500 [==============================] - 0s 189us/step - loss: 4.9033 - val_loss: 201.5987\n",
      "Epoch 200/1000\n",
      "1500/1500 [==============================] - 0s 112us/step - loss: 4.6229 - val_loss: 204.4572\n",
      "Epoch 201/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 4.3862 - val_loss: 203.2050\n",
      "Epoch 202/1000\n",
      "1500/1500 [==============================] - 0s 109us/step - loss: 3.6938 - val_loss: 201.9103\n",
      "Epoch 203/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 3.5498 - val_loss: 203.7508\n",
      "Epoch 204/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 3.5904 - val_loss: 203.8020\n",
      "Epoch 205/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 4.0755 - val_loss: 205.5046\n",
      "Epoch 206/1000\n",
      "1500/1500 [==============================] - 0s 111us/step - loss: 3.8116 - val_loss: 204.2973\n",
      "Epoch 207/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 3.1122 - val_loss: 204.5875\n",
      "Epoch 208/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 2.8386 - val_loss: 204.1863\n",
      "Epoch 209/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 2.6152 - val_loss: 205.9988\n",
      "Epoch 210/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 2.5403 - val_loss: 206.5114\n",
      "Epoch 211/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 2.9497 - val_loss: 205.7357\n",
      "Epoch 212/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 2.4062 - val_loss: 208.4827\n",
      "Epoch 213/1000\n",
      "1500/1500 [==============================] - 0s 119us/step - loss: 2.4099 - val_loss: 208.8360\n",
      "Epoch 214/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 2.4872 - val_loss: 209.7735\n",
      "Epoch 215/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 2.4031 - val_loss: 208.0311\n",
      "Epoch 216/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 2.4572 - val_loss: 210.2347\n",
      "Epoch 217/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 2.0575 - val_loss: 208.3085\n",
      "Epoch 218/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 3.1736 - val_loss: 208.9066\n",
      "Epoch 219/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 3.1902 - val_loss: 208.3265\n",
      "Epoch 220/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 2.6929 - val_loss: 208.8621\n",
      "Epoch 221/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 2.9062 - val_loss: 208.0858\n",
      "Epoch 222/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 1.7533 - val_loss: 208.9184\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 105us/step - loss: 1.5992 - val_loss: 208.4109\n",
      "Epoch 224/1000\n",
      "1500/1500 [==============================] - 0s 109us/step - loss: 1.5448 - val_loss: 210.8487\n",
      "Epoch 225/1000\n",
      "1500/1500 [==============================] - 0s 111us/step - loss: 1.4739 - val_loss: 210.6988\n",
      "Epoch 226/1000\n",
      "1500/1500 [==============================] - 0s 112us/step - loss: 1.4694 - val_loss: 210.8867\n",
      "Epoch 227/1000\n",
      "1500/1500 [==============================] - 0s 112us/step - loss: 1.6154 - val_loss: 210.0163\n",
      "Epoch 228/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 1.3346 - val_loss: 209.7763\n",
      "Epoch 229/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 1.3096 - val_loss: 210.5892\n",
      "Epoch 230/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 1.2279 - val_loss: 210.2039\n",
      "Epoch 231/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.1866 - val_loss: 211.2267\n",
      "Epoch 232/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.2071 - val_loss: 210.4266\n",
      "Epoch 233/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 1.1281 - val_loss: 209.9523\n",
      "Epoch 234/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 1.0770 - val_loss: 212.3531\n",
      "Epoch 235/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 1.1173 - val_loss: 211.0232\n",
      "Epoch 236/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 1.0549 - val_loss: 211.3108\n",
      "Epoch 237/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 1.2014 - val_loss: 212.2704\n",
      "Epoch 238/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 1.8515 - val_loss: 214.4311\n",
      "Epoch 239/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 1.4989 - val_loss: 212.3098\n",
      "Epoch 240/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 1.1185 - val_loss: 211.3212\n",
      "Epoch 241/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.9340 - val_loss: 212.2338\n",
      "Epoch 242/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.8565 - val_loss: 211.8794\n",
      "Epoch 243/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 1.2068 - val_loss: 215.1170\n",
      "Epoch 244/1000\n",
      "1500/1500 [==============================] - 0s 161us/step - loss: 1.3460 - val_loss: 211.8872\n",
      "Epoch 245/1000\n",
      "1500/1500 [==============================] - 0s 191us/step - loss: 1.2062 - val_loss: 213.9425\n",
      "Epoch 246/1000\n",
      "1500/1500 [==============================] - 0s 177us/step - loss: 1.9638 - val_loss: 213.7312\n",
      "Epoch 247/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 1.2022 - val_loss: 213.8612\n",
      "Epoch 248/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 2.3496 - val_loss: 212.8850\n",
      "Epoch 249/1000\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 1.6793 - val_loss: 215.3712\n",
      "Epoch 250/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 2.6759 - val_loss: 211.7188\n",
      "Epoch 251/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 1.1999 - val_loss: 213.2312\n",
      "Epoch 252/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 1.6542 - val_loss: 212.9758\n",
      "Epoch 253/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 1.3539 - val_loss: 211.1843\n",
      "Epoch 254/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.9066 - val_loss: 211.8076\n",
      "Epoch 255/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 1.2508 - val_loss: 212.3893\n",
      "Epoch 256/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 1.8367 - val_loss: 212.2820\n",
      "Epoch 257/1000\n",
      "1500/1500 [==============================] - 0s 112us/step - loss: 1.0281 - val_loss: 213.5022\n",
      "Epoch 258/1000\n",
      "1500/1500 [==============================] - 0s 116us/step - loss: 0.8330 - val_loss: 212.4071\n",
      "Epoch 259/1000\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 1.6107 - val_loss: 214.6869\n",
      "Epoch 260/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 1.9176 - val_loss: 212.0675\n",
      "Epoch 261/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 1.3900 - val_loss: 213.4739\n",
      "Epoch 262/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 1.1763 - val_loss: 213.4453\n",
      "Epoch 263/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 1.7556 - val_loss: 218.9473\n",
      "Epoch 264/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 1.8638 - val_loss: 212.7703\n",
      "Epoch 265/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 1.3716 - val_loss: 212.2379\n",
      "Epoch 266/1000\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 0.8209 - val_loss: 213.1906\n",
      "Epoch 267/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.6692 - val_loss: 214.4686\n",
      "Epoch 268/1000\n",
      "1500/1500 [==============================] - 0s 146us/step - loss: 0.5405 - val_loss: 214.7218\n",
      "Epoch 269/1000\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 0.5109 - val_loss: 214.8803\n",
      "Epoch 270/1000\n",
      "1500/1500 [==============================] - 0s 146us/step - loss: 0.5945 - val_loss: 214.5294\n",
      "Epoch 271/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 0.6001 - val_loss: 214.4848\n",
      "Epoch 272/1000\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 0.6217 - val_loss: 215.2229\n",
      "Epoch 273/1000\n",
      "1500/1500 [==============================] - 0s 146us/step - loss: 0.5077 - val_loss: 214.5130\n",
      "Epoch 274/1000\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 0.6728 - val_loss: 215.9604\n",
      "Epoch 275/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 1.0980 - val_loss: 216.0479\n",
      "Epoch 276/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.7732 - val_loss: 217.6536\n",
      "Epoch 277/1000\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 2.7059 - val_loss: 213.5421\n",
      "Epoch 278/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 3.3019 - val_loss: 229.0433\n",
      "Epoch 279/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 5.2439 - val_loss: 211.5321\n",
      "Epoch 280/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 2.0986 - val_loss: 214.5331\n",
      "Epoch 281/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 2.0979 - val_loss: 216.8480\n",
      "Epoch 282/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 1.4953 - val_loss: 213.4461\n",
      "Epoch 283/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 1.9032 - val_loss: 216.5802\n",
      "Epoch 284/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 1.3447 - val_loss: 214.2921\n",
      "Epoch 285/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.6895 - val_loss: 214.0674\n",
      "Epoch 286/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.4617 - val_loss: 214.0722\n",
      "Epoch 287/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.4646 - val_loss: 213.7170\n",
      "Epoch 288/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 0.4521 - val_loss: 214.5153\n",
      "Epoch 289/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.3498 - val_loss: 214.6868\n",
      "Epoch 290/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.3347 - val_loss: 214.2213\n",
      "Epoch 291/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.3254 - val_loss: 215.0766\n",
      "Epoch 292/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.2721 - val_loss: 214.8157\n",
      "Epoch 293/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.3199 - val_loss: 214.8735\n",
      "Epoch 294/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.3411 - val_loss: 214.9704\n",
      "Epoch 295/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.3701 - val_loss: 215.3193\n",
      "Epoch 296/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 0.3529 - val_loss: 214.5010\n",
      "Epoch 297/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.3466 - val_loss: 215.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.3437 - val_loss: 215.1580\n",
      "Epoch 299/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 0.6958 - val_loss: 215.6341\n",
      "Epoch 300/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 1.7333 - val_loss: 216.2555\n",
      "Epoch 301/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 1.7192 - val_loss: 225.0968\n",
      "Epoch 302/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 2.7015 - val_loss: 215.1754\n",
      "Epoch 303/1000\n",
      "1500/1500 [==============================] - 0s 107us/step - loss: 1.4671 - val_loss: 217.2977\n",
      "Epoch 304/1000\n",
      "1500/1500 [==============================] - 0s 119us/step - loss: 4.1137 - val_loss: 220.3982\n",
      "Epoch 305/1000\n",
      "1500/1500 [==============================] - 0s 110us/step - loss: 5.0336 - val_loss: 217.6466\n",
      "Epoch 306/1000\n",
      "1500/1500 [==============================] - 0s 112us/step - loss: 2.2919 - val_loss: 214.5277\n",
      "Epoch 307/1000\n",
      "1500/1500 [==============================] - 0s 112us/step - loss: 3.5506 - val_loss: 214.4455\n",
      "Epoch 308/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 2.0714 - val_loss: 214.3271\n",
      "Epoch 309/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 1.2242 - val_loss: 214.4338\n",
      "Epoch 310/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.5878 - val_loss: 214.6144\n",
      "Epoch 311/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.5135 - val_loss: 213.5014\n",
      "Epoch 312/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.3583 - val_loss: 214.1067\n",
      "Epoch 313/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 0.3267 - val_loss: 214.4109\n",
      "Epoch 314/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 0.2545 - val_loss: 214.1046\n",
      "Epoch 315/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.2422 - val_loss: 214.4803\n",
      "Epoch 316/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.3903 - val_loss: 214.9934\n",
      "Epoch 317/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 0.3813 - val_loss: 214.8099\n",
      "Epoch 318/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.2694 - val_loss: 214.0716\n",
      "Epoch 319/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.2434 - val_loss: 214.0222\n",
      "Epoch 320/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.2124 - val_loss: 214.6876\n",
      "Epoch 321/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.2983 - val_loss: 214.8672\n",
      "Epoch 322/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.9812 - val_loss: 215.1497\n",
      "Epoch 323/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 0.6625 - val_loss: 215.6825\n",
      "Epoch 324/1000\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.608 - 0s 83us/step - loss: 0.6051 - val_loss: 214.6809\n",
      "Epoch 325/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 0.4405 - val_loss: 215.1130\n",
      "Epoch 326/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.2610 - val_loss: 214.6644\n",
      "Epoch 327/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.2391 - val_loss: 215.0585\n",
      "Epoch 328/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 0.2417 - val_loss: 214.4822\n",
      "Epoch 329/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.2109 - val_loss: 215.3945\n",
      "Epoch 330/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 1.2154 - val_loss: 214.8333\n",
      "Epoch 331/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 2.9868 - val_loss: 220.7954\n",
      "Epoch 332/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 3.0870 - val_loss: 215.6950\n",
      "Epoch 333/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 3.0755 - val_loss: 217.7142\n",
      "Epoch 334/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 5.0692 - val_loss: 217.1729\n",
      "Epoch 335/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 1.6122 - val_loss: 221.9721\n",
      "Epoch 336/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 2.9867 - val_loss: 212.8503\n",
      "Epoch 337/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 1.1256 - val_loss: 215.7797\n",
      "Epoch 338/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.6410 - val_loss: 215.6490\n",
      "Epoch 339/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.5115 - val_loss: 215.4837\n",
      "Epoch 340/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.3398 - val_loss: 214.9833\n",
      "Epoch 341/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.2820 - val_loss: 213.9947\n",
      "Epoch 342/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.3087 - val_loss: 214.6219\n",
      "Epoch 343/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.2098 - val_loss: 215.0361\n",
      "Epoch 344/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 0.2323 - val_loss: 215.0299\n",
      "Epoch 345/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.1768 - val_loss: 214.8135\n",
      "Epoch 346/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.1550 - val_loss: 215.1028\n",
      "Epoch 347/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.1963 - val_loss: 214.7345\n",
      "Epoch 348/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 0.2724 - val_loss: 213.8147\n",
      "Epoch 349/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.2663 - val_loss: 214.9208\n",
      "Epoch 350/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.4094 - val_loss: 213.8248\n",
      "Epoch 351/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 0.8132 - val_loss: 215.8489\n",
      "Epoch 352/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.7602 - val_loss: 212.3689\n",
      "Epoch 353/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 0.4178 - val_loss: 214.8847\n",
      "Epoch 354/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 0.4767 - val_loss: 215.4534\n",
      "Epoch 355/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 0.5307 - val_loss: 215.3372\n",
      "Epoch 356/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.4362 - val_loss: 214.5112\n",
      "Epoch 357/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.7998 - val_loss: 214.6181\n",
      "Epoch 358/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.7111 - val_loss: 214.6122\n",
      "Epoch 359/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.4884 - val_loss: 215.3698\n",
      "Epoch 360/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.4875 - val_loss: 215.2923\n",
      "Epoch 361/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.6951 - val_loss: 215.1311\n",
      "Epoch 362/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 1.3742 - val_loss: 221.1393\n",
      "Epoch 363/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 1.5257 - val_loss: 215.6657\n",
      "Epoch 364/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 0.6135 - val_loss: 215.0490\n",
      "Epoch 365/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 1.2075 - val_loss: 212.9970\n",
      "Epoch 366/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 2.4158 - val_loss: 212.1799\n",
      "Epoch 367/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 1.1375 - val_loss: 213.4731\n",
      "Epoch 368/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 0.9172 - val_loss: 214.1951\n",
      "Epoch 369/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 2.4073 - val_loss: 212.8424\n",
      "Epoch 370/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 2.6507 - val_loss: 213.9900\n",
      "Epoch 371/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 1.2085 - val_loss: 213.1316\n",
      "Epoch 372/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.6829 - val_loss: 213.6022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 373/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.5527 - val_loss: 214.4583\n",
      "Epoch 374/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.3825 - val_loss: 215.0442\n",
      "Epoch 375/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 1.2403 - val_loss: 214.5164\n",
      "Epoch 376/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 1.0476 - val_loss: 212.8607\n",
      "Epoch 377/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 0.8622 - val_loss: 214.8362\n",
      "Epoch 378/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 1.2660 - val_loss: 214.0891\n",
      "Epoch 379/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 1.3530 - val_loss: 214.9126\n",
      "Epoch 380/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.9848 - val_loss: 214.5586\n",
      "Epoch 381/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 1.7643 - val_loss: 217.4274\n",
      "Epoch 382/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 2.2316 - val_loss: 212.8059\n",
      "Epoch 383/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 1.3756 - val_loss: 214.3453\n",
      "Epoch 384/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.9347 - val_loss: 216.0725\n",
      "Epoch 385/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.8537 - val_loss: 214.3065\n",
      "Epoch 386/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 1.0231 - val_loss: 214.5022\n",
      "Epoch 387/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.9886 - val_loss: 213.7722\n",
      "Epoch 388/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.4725 - val_loss: 213.0923\n",
      "Epoch 389/1000\n",
      "1500/1500 [==============================] - 0s 209us/step - loss: 0.2830 - val_loss: 214.3341\n",
      "Epoch 390/1000\n",
      "1500/1500 [==============================] - 0s 164us/step - loss: 0.3063 - val_loss: 214.0268\n",
      "Epoch 391/1000\n",
      "1500/1500 [==============================] - 0s 165us/step - loss: 0.3592 - val_loss: 213.5750\n",
      "Epoch 392/1000\n",
      "1500/1500 [==============================] - 0s 163us/step - loss: 0.2345 - val_loss: 213.4430\n",
      "Epoch 393/1000\n",
      "1500/1500 [==============================] - 0s 166us/step - loss: 0.1614 - val_loss: 214.6174\n",
      "Epoch 394/1000\n",
      "1500/1500 [==============================] - 0s 162us/step - loss: 0.1792 - val_loss: 215.0055\n",
      "Epoch 395/1000\n",
      "1500/1500 [==============================] - 0s 167us/step - loss: 0.3293 - val_loss: 215.7037\n",
      "Epoch 396/1000\n",
      "1500/1500 [==============================] - 0s 163us/step - loss: 0.6293 - val_loss: 215.2376\n",
      "Epoch 397/1000\n",
      "1500/1500 [==============================] - 0s 164us/step - loss: 1.4428 - val_loss: 221.1344\n",
      "Epoch 398/1000\n",
      "1500/1500 [==============================] - 0s 164us/step - loss: 2.6664 - val_loss: 214.9994\n",
      "Epoch 399/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 5.6111 - val_loss: 216.2468\n",
      "Epoch 400/1000\n",
      "1500/1500 [==============================] - 0s 116us/step - loss: 10.0765 - val_loss: 223.6365\n",
      "Epoch 401/1000\n",
      "1500/1500 [==============================] - 0s 117us/step - loss: 6.4481 - val_loss: 213.3719\n",
      "Epoch 402/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 1.8844 - val_loss: 212.3797\n",
      "Epoch 403/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.7719 - val_loss: 212.7150\n",
      "Epoch 404/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.9569 - val_loss: 212.9543\n",
      "Epoch 405/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.6757 - val_loss: 214.3141\n",
      "Epoch 406/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.5374 - val_loss: 213.3437\n",
      "Epoch 407/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.2839 - val_loss: 213.7281\n",
      "Epoch 408/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.2304 - val_loss: 214.0319\n",
      "Epoch 409/1000\n",
      "1500/1500 [==============================] - 0s 118us/step - loss: 0.1719 - val_loss: 213.2992\n",
      "Epoch 410/1000\n",
      "1500/1500 [==============================] - 0s 112us/step - loss: 0.2259 - val_loss: 213.3902\n",
      "Epoch 411/1000\n",
      "1500/1500 [==============================] - 0s 114us/step - loss: 0.1859 - val_loss: 213.5912\n",
      "Epoch 412/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.1057 - val_loss: 213.3088\n",
      "Epoch 413/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.1109 - val_loss: 213.6744\n",
      "Epoch 414/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.1112 - val_loss: 213.4031\n",
      "Epoch 415/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.1772 - val_loss: 213.7694\n",
      "Epoch 416/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.1545 - val_loss: 213.2592\n",
      "Epoch 417/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.0935 - val_loss: 213.6739\n",
      "Epoch 418/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 0.0954 - val_loss: 213.8250\n",
      "Epoch 419/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.0790 - val_loss: 214.2089\n",
      "Epoch 420/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 0.1300 - val_loss: 213.8988\n",
      "Epoch 421/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.1243 - val_loss: 213.8080\n",
      "Epoch 422/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.3192 - val_loss: 212.5491\n",
      "Epoch 423/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 1.1792 - val_loss: 214.3281\n",
      "Epoch 424/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 1.6136 - val_loss: 214.3618\n",
      "Epoch 425/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 1.4712 - val_loss: 218.0831\n",
      "Epoch 426/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 1.4155 - val_loss: 215.1284\n",
      "Epoch 427/1000\n",
      "1500/1500 [==============================] - 0s 80us/step - loss: 0.6911 - val_loss: 214.9608\n",
      "Epoch 428/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 1.0115 - val_loss: 212.7851\n",
      "Epoch 429/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 1.5607 - val_loss: 212.3439\n",
      "Epoch 430/1000\n",
      "1500/1500 [==============================] - 0s 175us/step - loss: 0.9184 - val_loss: 213.0132\n",
      "Epoch 431/1000\n",
      "1500/1500 [==============================] - 0s 178us/step - loss: 0.6295 - val_loss: 214.1617\n",
      "Epoch 432/1000\n",
      "1500/1500 [==============================] - 0s 175us/step - loss: 1.3186 - val_loss: 212.6400\n",
      "Epoch 433/1000\n",
      "1500/1500 [==============================] - 0s 175us/step - loss: 0.7936 - val_loss: 212.6332\n",
      "Epoch 434/1000\n",
      "1500/1500 [==============================] - 0s 174us/step - loss: 0.9265 - val_loss: 211.3861\n",
      "Epoch 435/1000\n",
      "1500/1500 [==============================] - 0s 176us/step - loss: 0.6087 - val_loss: 212.9853\n",
      "Epoch 436/1000\n",
      "1500/1500 [==============================] - 0s 176us/step - loss: 0.7530 - val_loss: 212.8190\n",
      "Epoch 437/1000\n",
      "1500/1500 [==============================] - 0s 176us/step - loss: 0.4718 - val_loss: 212.3987\n",
      "Epoch 438/1000\n",
      "1500/1500 [==============================] - 0s 174us/step - loss: 0.5135 - val_loss: 212.1763\n",
      "Epoch 439/1000\n",
      "1500/1500 [==============================] - 0s 173us/step - loss: 1.1117 - val_loss: 212.6053\n",
      "Epoch 440/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 2.1499 - val_loss: 214.9932\n",
      "Epoch 441/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 2.5194 - val_loss: 211.7938\n",
      "Epoch 442/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 1.1485 - val_loss: 211.2100\n",
      "Epoch 443/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 0.4975 - val_loss: 213.0664\n",
      "Epoch 444/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 0.4202 - val_loss: 213.6272\n",
      "Epoch 445/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 0.7375 - val_loss: 213.4052\n",
      "Epoch 446/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 1.4223 - val_loss: 212.8400\n",
      "Epoch 447/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 107us/step - loss: 0.7945 - val_loss: 212.3450\n",
      "Epoch 448/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 0.4066 - val_loss: 213.4011\n",
      "Epoch 449/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 0.2617 - val_loss: 212.3942\n",
      "Epoch 450/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.2412 - val_loss: 212.1082\n",
      "Epoch 451/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 0.1729 - val_loss: 213.0231\n",
      "Epoch 452/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 0.1744 - val_loss: 212.8858\n",
      "Epoch 453/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 0.5002 - val_loss: 212.4517\n",
      "Epoch 454/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 0.8477 - val_loss: 213.3621\n",
      "Epoch 455/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 1.2362 - val_loss: 213.0153\n",
      "Epoch 456/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 0.8283 - val_loss: 211.9634\n",
      "Epoch 457/1000\n",
      "1500/1500 [==============================] - 0s 115us/step - loss: 0.6753 - val_loss: 213.5901\n",
      "Epoch 458/1000\n",
      "1500/1500 [==============================] - 0s 115us/step - loss: 0.5786 - val_loss: 211.9571\n",
      "Epoch 459/1000\n",
      "1500/1500 [==============================] - 0s 116us/step - loss: 0.3152 - val_loss: 212.8337\n",
      "Epoch 460/1000\n",
      "1500/1500 [==============================] - 0s 117us/step - loss: 0.1933 - val_loss: 212.2537\n",
      "Epoch 461/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 0.5084 - val_loss: 214.0487\n",
      "Epoch 462/1000\n",
      "1500/1500 [==============================] - 0s 118us/step - loss: 1.0107 - val_loss: 213.6758\n",
      "Epoch 463/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 2.5595 - val_loss: 214.7002\n",
      "Epoch 464/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 1.2577 - val_loss: 212.9366\n",
      "Epoch 465/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.9956 - val_loss: 213.5331\n",
      "Epoch 466/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 1.2263 - val_loss: 212.9118\n",
      "Epoch 467/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.5676 - val_loss: 212.8892\n",
      "Epoch 468/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 0.3476 - val_loss: 212.2284\n",
      "Epoch 469/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.3496 - val_loss: 213.6702\n",
      "Epoch 470/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 1.0579 - val_loss: 215.3442\n",
      "Epoch 471/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 1.4460 - val_loss: 212.7949\n",
      "Epoch 472/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.5460 - val_loss: 214.6693\n",
      "Epoch 473/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 1.2151 - val_loss: 211.1659\n",
      "Epoch 474/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.7718 - val_loss: 214.2604\n",
      "Epoch 475/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.5148 - val_loss: 213.4478\n",
      "Epoch 476/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.4761 - val_loss: 212.1271\n",
      "Epoch 477/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.4773 - val_loss: 211.7244\n",
      "Epoch 478/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 1.1921 - val_loss: 212.3102\n",
      "Epoch 479/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 2.6967 - val_loss: 212.6565\n",
      "Epoch 480/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 1.3167 - val_loss: 215.7537\n",
      "Epoch 481/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 2.7423 - val_loss: 210.2118\n",
      "Epoch 482/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 1.2559 - val_loss: 212.0017\n",
      "Epoch 483/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.8448 - val_loss: 211.1745\n",
      "Epoch 484/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.4518 - val_loss: 211.1554\n",
      "Epoch 485/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.3870 - val_loss: 213.2543\n",
      "Epoch 486/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 0.3041 - val_loss: 211.9300\n",
      "Epoch 487/1000\n",
      "1500/1500 [==============================] - 0s 117us/step - loss: 0.1726 - val_loss: 211.5840\n",
      "Epoch 488/1000\n",
      "1500/1500 [==============================] - 0s 116us/step - loss: 0.2300 - val_loss: 212.0318\n",
      "Epoch 489/1000\n",
      "1500/1500 [==============================] - 0s 117us/step - loss: 0.2760 - val_loss: 211.1176\n",
      "Epoch 490/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.1139 - val_loss: 212.1035\n",
      "Epoch 491/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.6265 - val_loss: 210.8114\n",
      "Epoch 492/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 1.9875 - val_loss: 216.5123\n",
      "Epoch 493/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 4.0063 - val_loss: 211.7951\n",
      "Epoch 494/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 2.1662 - val_loss: 214.6380\n",
      "Epoch 495/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.9999 - val_loss: 211.8370\n",
      "Epoch 496/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.4947 - val_loss: 212.0882\n",
      "Epoch 497/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.4216 - val_loss: 212.1123\n",
      "Epoch 498/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.3769 - val_loss: 213.7537\n",
      "Epoch 499/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.6526 - val_loss: 211.4262\n",
      "Epoch 500/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.4333 - val_loss: 212.5143\n",
      "Epoch 501/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.1655 - val_loss: 211.5891\n",
      "Epoch 502/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.1915 - val_loss: 211.9697\n",
      "Epoch 503/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.1598 - val_loss: 211.4903\n",
      "Epoch 504/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.1811 - val_loss: 211.4597\n",
      "Epoch 505/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 2.6411 - val_loss: 212.2489\n",
      "Epoch 506/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 3.8489 - val_loss: 210.5754\n",
      "Epoch 507/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 2.3191 - val_loss: 212.7290\n",
      "Epoch 508/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 1.3338 - val_loss: 212.1461\n",
      "Epoch 509/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.5026 - val_loss: 211.7920\n",
      "Epoch 510/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.5211 - val_loss: 211.7407\n",
      "Epoch 511/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.4533 - val_loss: 212.1363\n",
      "Epoch 512/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.6418 - val_loss: 213.8935\n",
      "Epoch 513/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.7816 - val_loss: 211.4974\n",
      "Epoch 514/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.5825 - val_loss: 212.0636\n",
      "Epoch 515/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.3988 - val_loss: 212.1629\n",
      "Epoch 516/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.1662 - val_loss: 211.8888\n",
      "Epoch 517/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 0.1069 - val_loss: 211.7078\n",
      "Epoch 518/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.3349 - val_loss: 211.9118\n",
      "Epoch 519/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.3024 - val_loss: 211.7060\n",
      "Epoch 520/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.2008 - val_loss: 211.8376\n",
      "Epoch 521/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.6114 - val_loss: 212.6398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 522/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 2.0784 - val_loss: 210.6238\n",
      "Epoch 523/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 0.8956 - val_loss: 213.6076\n",
      "Epoch 524/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.6488 - val_loss: 211.9909\n",
      "Epoch 525/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.4530 - val_loss: 211.1943\n",
      "Epoch 526/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 1.1502 - val_loss: 214.8672\n",
      "Epoch 527/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.4760 - val_loss: 211.3553\n",
      "Epoch 528/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.2514 - val_loss: 212.9003\n",
      "Epoch 529/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.2037 - val_loss: 212.4268\n",
      "Epoch 530/1000\n",
      "1500/1500 [==============================] - 0s 79us/step - loss: 0.2429 - val_loss: 212.9229\n",
      "Epoch 531/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.3501 - val_loss: 211.5771\n",
      "Epoch 532/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.1963 - val_loss: 212.1690\n",
      "Epoch 533/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.3797 - val_loss: 213.6629\n",
      "Epoch 534/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.5121 - val_loss: 213.7411\n",
      "Epoch 535/1000\n",
      "1500/1500 [==============================] - 0s 118us/step - loss: 1.0767 - val_loss: 214.7015\n",
      "Epoch 536/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.4869 - val_loss: 213.2456\n",
      "Epoch 537/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.5692 - val_loss: 212.4202\n",
      "Epoch 538/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 0.3076 - val_loss: 212.9526\n",
      "Epoch 539/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.5760 - val_loss: 213.3773\n",
      "Epoch 540/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.5503 - val_loss: 213.1187\n",
      "Epoch 541/1000\n",
      "1500/1500 [==============================] - 0s 174us/step - loss: 0.9679 - val_loss: 210.3675\n",
      "Epoch 542/1000\n",
      "1500/1500 [==============================] - 0s 174us/step - loss: 0.8665 - val_loss: 212.9828\n",
      "Epoch 543/1000\n",
      "1500/1500 [==============================] - 0s 174us/step - loss: 5.2485 - val_loss: 220.5157\n",
      "Epoch 544/1000\n",
      "1500/1500 [==============================] - 0s 170us/step - loss: 3.9000 - val_loss: 211.3129\n",
      "Epoch 545/1000\n",
      "1500/1500 [==============================] - 0s 173us/step - loss: 2.6232 - val_loss: 211.3346\n",
      "Epoch 546/1000\n",
      "1500/1500 [==============================] - 0s 174us/step - loss: 0.8864 - val_loss: 211.5134\n",
      "Epoch 547/1000\n",
      "1500/1500 [==============================] - 0s 177us/step - loss: 0.5332 - val_loss: 211.0531\n",
      "Epoch 548/1000\n",
      "1500/1500 [==============================] - 0s 175us/step - loss: 0.3983 - val_loss: 211.3863\n",
      "Epoch 549/1000\n",
      "1500/1500 [==============================] - 0s 171us/step - loss: 0.2270 - val_loss: 210.4021\n",
      "Epoch 550/1000\n",
      "1500/1500 [==============================] - 0s 111us/step - loss: 0.2140 - val_loss: 211.0965\n",
      "Epoch 551/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.1766 - val_loss: 210.7753\n",
      "Epoch 552/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.2462 - val_loss: 211.1864\n",
      "Epoch 553/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.1102 - val_loss: 211.2757\n",
      "Epoch 554/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.1073 - val_loss: 211.2594\n",
      "Epoch 555/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 0.1827 - val_loss: 210.8537\n",
      "Epoch 556/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.1553 - val_loss: 210.6308\n",
      "Epoch 557/1000\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 0.0783 - val_loss: 210.7054\n",
      "Epoch 558/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.1065 - val_loss: 210.3878\n",
      "Epoch 559/1000\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 0.1215 - val_loss: 210.9439\n",
      "Epoch 560/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.4714 - val_loss: 211.5342\n",
      "Epoch 561/1000\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 0.6822 - val_loss: 212.4983\n",
      "Epoch 562/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 1.3472 - val_loss: 211.3863\n",
      "Epoch 563/1000\n",
      "1500/1500 [==============================] - 0s 116us/step - loss: 2.1496 - val_loss: 210.3416\n",
      "Epoch 564/1000\n",
      "1500/1500 [==============================] - 0s 115us/step - loss: 1.0614 - val_loss: 212.8095\n",
      "Epoch 565/1000\n",
      "1500/1500 [==============================] - 0s 117us/step - loss: 0.4620 - val_loss: 211.1702\n",
      "Epoch 566/1000\n",
      "1500/1500 [==============================] - 0s 114us/step - loss: 0.5375 - val_loss: 210.8022\n",
      "Epoch 567/1000\n",
      "1500/1500 [==============================] - 0s 116us/step - loss: 1.7808 - val_loss: 222.5369\n",
      "Epoch 568/1000\n",
      "1500/1500 [==============================] - 0s 116us/step - loss: 1.9088 - val_loss: 208.7035\n",
      "Epoch 569/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 0.7766 - val_loss: 211.9385\n",
      "Epoch 570/1000\n",
      "1500/1500 [==============================] - 0s 111us/step - loss: 1.0246 - val_loss: 212.0610\n",
      "Epoch 571/1000\n",
      "1500/1500 [==============================] - 0s 113us/step - loss: 0.5296 - val_loss: 211.0525\n",
      "Epoch 572/1000\n",
      "1500/1500 [==============================] - 0s 167us/step - loss: 0.5464 - val_loss: 210.6256\n",
      "Epoch 573/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.5570 - val_loss: 208.7133\n",
      "Epoch 574/1000\n",
      "1500/1500 [==============================] - 0s 118us/step - loss: 0.3922 - val_loss: 209.9703\n",
      "Epoch 575/1000\n",
      "1500/1500 [==============================] - 0s 119us/step - loss: 0.3578 - val_loss: 209.6479\n",
      "Epoch 576/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 0.3171 - val_loss: 210.3835\n",
      "Epoch 577/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 0.3099 - val_loss: 209.2676\n",
      "Epoch 578/1000\n",
      "1500/1500 [==============================] - 0s 110us/step - loss: 0.2536 - val_loss: 210.1884\n",
      "Epoch 579/1000\n",
      "1500/1500 [==============================] - 0s 111us/step - loss: 0.4245 - val_loss: 210.8110\n",
      "Epoch 580/1000\n",
      "1500/1500 [==============================] - 0s 115us/step - loss: 0.3631 - val_loss: 212.7844\n",
      "Epoch 581/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 1.6489 - val_loss: 213.7270\n",
      "Epoch 582/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 5.7112 - val_loss: 209.9617\n",
      "Epoch 583/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 1.4494 - val_loss: 210.8544\n",
      "Epoch 584/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.6778 - val_loss: 210.4812\n",
      "Epoch 585/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.8288 - val_loss: 210.3805\n",
      "Epoch 586/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.4805 - val_loss: 211.0408\n",
      "Epoch 587/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.4370 - val_loss: 210.8903\n",
      "Epoch 588/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.2109 - val_loss: 209.9883\n",
      "Epoch 589/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.1714 - val_loss: 209.9009\n",
      "Epoch 590/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.1605 - val_loss: 211.4835\n",
      "Epoch 591/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.1634 - val_loss: 209.8515\n",
      "Epoch 592/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.1058 - val_loss: 209.5147\n",
      "Epoch 593/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.2032 - val_loss: 210.6078\n",
      "Epoch 594/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 0.1069 - val_loss: 210.2129\n",
      "Epoch 595/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.0867 - val_loss: 210.1110\n",
      "Epoch 596/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.0846 - val_loss: 210.0688\n",
      "Epoch 597/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.0719 - val_loss: 210.9725\n",
      "Epoch 598/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.0938 - val_loss: 210.0857\n",
      "Epoch 599/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.2258 - val_loss: 210.2667\n",
      "Epoch 600/1000\n",
      "1500/1500 [==============================] - 0s 113us/step - loss: 0.2571 - val_loss: 210.8123\n",
      "Epoch 601/1000\n",
      "1500/1500 [==============================] - 0s 113us/step - loss: 0.5528 - val_loss: 209.7256\n",
      "Epoch 602/1000\n",
      "1500/1500 [==============================] - 0s 112us/step - loss: 0.3915 - val_loss: 211.0449\n",
      "Epoch 603/1000\n",
      "1500/1500 [==============================] - 0s 111us/step - loss: 0.3932 - val_loss: 209.7643\n",
      "Epoch 604/1000\n",
      "1500/1500 [==============================] - 0s 113us/step - loss: 0.8569 - val_loss: 211.3156\n",
      "Epoch 605/1000\n",
      "1500/1500 [==============================] - 0s 112us/step - loss: 6.3517 - val_loss: 209.9548\n",
      "Epoch 606/1000\n",
      "1500/1500 [==============================] - 0s 111us/step - loss: 2.9532 - val_loss: 210.9482\n",
      "Epoch 607/1000\n",
      "1500/1500 [==============================] - 0s 110us/step - loss: 1.1125 - val_loss: 210.6587\n",
      "Epoch 608/1000\n",
      "1500/1500 [==============================] - 0s 112us/step - loss: 0.8154 - val_loss: 209.8972\n",
      "Epoch 609/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 1.2140 - val_loss: 210.2999\n",
      "Epoch 610/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 1.4197 - val_loss: 211.7751\n",
      "Epoch 611/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 0.7398 - val_loss: 210.8418\n",
      "Epoch 612/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.4096 - val_loss: 208.9956\n",
      "Epoch 613/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.6401 - val_loss: 210.5825\n",
      "Epoch 614/1000\n",
      "1500/1500 [==============================] - 0s 126us/step - loss: 0.3815 - val_loss: 209.0685\n",
      "Epoch 615/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.3376 - val_loss: 209.8412\n",
      "Epoch 616/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.2899 - val_loss: 210.0017\n",
      "Epoch 617/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 0.2343 - val_loss: 210.6552\n",
      "Epoch 618/1000\n",
      "1500/1500 [==============================] - 0s 107us/step - loss: 0.1373 - val_loss: 209.7349\n",
      "Epoch 619/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 0.1179 - val_loss: 210.0295\n",
      "Epoch 620/1000\n",
      "1500/1500 [==============================] - 0s 107us/step - loss: 0.1226 - val_loss: 209.6847\n",
      "Epoch 621/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 0.0833 - val_loss: 209.3893\n",
      "Epoch 622/1000\n",
      "1500/1500 [==============================] - 0s 109us/step - loss: 0.1247 - val_loss: 209.8004\n",
      "Epoch 623/1000\n",
      "1500/1500 [==============================] - 0s 114us/step - loss: 0.1652 - val_loss: 210.1748\n",
      "Epoch 624/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 0.3727 - val_loss: 209.9635\n",
      "Epoch 625/1000\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 0.7482 - val_loss: 209.9681\n",
      "Epoch 626/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.5851 - val_loss: 209.7331\n",
      "Epoch 627/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.5947 - val_loss: 209.9072\n",
      "Epoch 628/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.8154 - val_loss: 209.7273\n",
      "Epoch 629/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 3.4176 - val_loss: 209.0410\n",
      "Epoch 630/1000\n",
      "1500/1500 [==============================] - 0s 220us/step - loss: 2.1526 - val_loss: 207.2405\n",
      "Epoch 631/1000\n",
      "1500/1500 [==============================] - 0s 224us/step - loss: 1.5292 - val_loss: 208.0586\n",
      "Epoch 632/1000\n",
      "1500/1500 [==============================] - 0s 225us/step - loss: 1.3553 - val_loss: 207.8182\n",
      "Epoch 633/1000\n",
      "1500/1500 [==============================] - 0s 221us/step - loss: 0.8779 - val_loss: 208.0566\n",
      "Epoch 634/1000\n",
      "1500/1500 [==============================] - 0s 226us/step - loss: 0.3084 - val_loss: 208.8816\n",
      "Epoch 635/1000\n",
      "1500/1500 [==============================] - 0s 229us/step - loss: 0.1876 - val_loss: 208.7818\n",
      "Epoch 636/1000\n",
      "1500/1500 [==============================] - 0s 191us/step - loss: 0.3947 - val_loss: 209.8877\n",
      "Epoch 637/1000\n",
      "1500/1500 [==============================] - 0s 179us/step - loss: 0.6399 - val_loss: 209.0159\n",
      "Epoch 638/1000\n",
      "1500/1500 [==============================] - 0s 176us/step - loss: 0.5828 - val_loss: 208.4422\n",
      "Epoch 639/1000\n",
      "1500/1500 [==============================] - 0s 174us/step - loss: 0.4817 - val_loss: 209.0498\n",
      "Epoch 640/1000\n",
      "1500/1500 [==============================] - 0s 169us/step - loss: 0.3484 - val_loss: 208.0154\n",
      "Epoch 641/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.4513 - val_loss: 208.6867\n",
      "Epoch 642/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.9169 - val_loss: 207.5951\n",
      "Epoch 643/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 0.6586 - val_loss: 208.5779\n",
      "Epoch 644/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.2705 - val_loss: 208.5831\n",
      "Epoch 645/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 0.9499 - val_loss: 212.8045\n",
      "Epoch 646/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 5.4470 - val_loss: 210.2251\n",
      "Epoch 647/1000\n",
      "1500/1500 [==============================] - 0s 102us/step - loss: 3.0649 - val_loss: 210.0064\n",
      "Epoch 648/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 1.5188 - val_loss: 210.0634\n",
      "Epoch 649/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 0.7707 - val_loss: 208.6909\n",
      "Epoch 650/1000\n",
      "1500/1500 [==============================] - 0s 111us/step - loss: 0.3533 - val_loss: 207.3055\n",
      "Epoch 651/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 0.3996 - val_loss: 208.0666\n",
      "Epoch 652/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 0.1854 - val_loss: 208.3567\n",
      "Epoch 653/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.1163 - val_loss: 207.9033\n",
      "Epoch 654/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.0950 - val_loss: 208.3543\n",
      "Epoch 655/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.0906 - val_loss: 208.1534\n",
      "Epoch 656/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.0603 - val_loss: 208.4733\n",
      "Epoch 657/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.0558 - val_loss: 208.0682\n",
      "Epoch 658/1000\n",
      "1500/1500 [==============================] - 0s 96us/step - loss: 0.0415 - val_loss: 208.3670\n",
      "Epoch 659/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.0942 - val_loss: 208.4835\n",
      "Epoch 660/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.2143 - val_loss: 209.0671\n",
      "Epoch 661/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 0.2290 - val_loss: 208.0162\n",
      "Epoch 662/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 0.5500 - val_loss: 208.5048\n",
      "Epoch 663/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.5721 - val_loss: 208.0934\n",
      "Epoch 664/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.4946 - val_loss: 208.6300\n",
      "Epoch 665/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.3587 - val_loss: 208.3349\n",
      "Epoch 666/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.3390 - val_loss: 209.4023\n",
      "Epoch 667/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 1.6426 - val_loss: 209.5219\n",
      "Epoch 668/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 8.0807 - val_loss: 211.3874\n",
      "Epoch 669/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 4.0250 - val_loss: 209.5622\n",
      "Epoch 670/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 127us/step - loss: 1.8384 - val_loss: 207.9520\n",
      "Epoch 671/1000\n",
      "1500/1500 [==============================] - 0s 127us/step - loss: 1.1532 - val_loss: 208.5769\n",
      "Epoch 672/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.5955 - val_loss: 208.4428\n",
      "Epoch 673/1000\n",
      "1500/1500 [==============================] - 0s 142us/step - loss: 0.2831 - val_loss: 207.7738\n",
      "Epoch 674/1000\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 0.1879 - val_loss: 208.0022\n",
      "Epoch 675/1000\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 0.1507 - val_loss: 207.7584\n",
      "Epoch 676/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.1882 - val_loss: 208.4743\n",
      "Epoch 677/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.6241 - val_loss: 207.8970\n",
      "Epoch 678/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.2860 - val_loss: 208.1447\n",
      "Epoch 679/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.1960 - val_loss: 208.5463\n",
      "Epoch 680/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 0.1753 - val_loss: 208.5187\n",
      "Epoch 681/1000\n",
      "1500/1500 [==============================] - 0s 112us/step - loss: 0.1466 - val_loss: 208.3293\n",
      "Epoch 682/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.1685 - val_loss: 208.9141\n",
      "Epoch 683/1000\n",
      "1500/1500 [==============================] - 0s 122us/step - loss: 0.1794 - val_loss: 208.6733\n",
      "Epoch 684/1000\n",
      "1500/1500 [==============================] - 0s 118us/step - loss: 0.2336 - val_loss: 208.3616\n",
      "Epoch 685/1000\n",
      "1500/1500 [==============================] - 0s 118us/step - loss: 0.1077 - val_loss: 208.0848\n",
      "Epoch 686/1000\n",
      "1500/1500 [==============================] - 0s 124us/step - loss: 0.0578 - val_loss: 208.1174\n",
      "Epoch 687/1000\n",
      "1500/1500 [==============================] - 0s 118us/step - loss: 0.0558 - val_loss: 208.1761\n",
      "Epoch 688/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.0796 - val_loss: 208.4098\n",
      "Epoch 689/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.0665 - val_loss: 208.1185\n",
      "Epoch 690/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 0.0815 - val_loss: 208.1001\n",
      "Epoch 691/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 0.1268 - val_loss: 208.0392\n",
      "Epoch 692/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.8306 - val_loss: 207.2521\n",
      "Epoch 693/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 2.8301 - val_loss: 207.7279\n",
      "Epoch 694/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 2.7691 - val_loss: 210.2517\n",
      "Epoch 695/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 2.1562 - val_loss: 209.4399\n",
      "Epoch 696/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 1.3406 - val_loss: 208.3992\n",
      "Epoch 697/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 1.0426 - val_loss: 206.4011\n",
      "Epoch 698/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 0.4455 - val_loss: 207.4304\n",
      "Epoch 699/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 0.2073 - val_loss: 207.6973\n",
      "Epoch 700/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 0.5659 - val_loss: 209.7944\n",
      "Epoch 701/1000\n",
      "1500/1500 [==============================] - 0s 159us/step - loss: 0.5071 - val_loss: 209.2253\n",
      "Epoch 702/1000\n",
      "1500/1500 [==============================] - 0s 157us/step - loss: 0.3835 - val_loss: 207.6987\n",
      "Epoch 703/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 0.1993 - val_loss: 208.3026\n",
      "Epoch 704/1000\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 0.0938 - val_loss: 207.7864\n",
      "Epoch 705/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.1054 - val_loss: 207.7033\n",
      "Epoch 706/1000\n",
      "1500/1500 [==============================] - 0s 140us/step - loss: 0.2575 - val_loss: 207.6227\n",
      "Epoch 707/1000\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 0.2799 - val_loss: 207.9668\n",
      "Epoch 708/1000\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 0.4369 - val_loss: 207.3042\n",
      "Epoch 709/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.2872 - val_loss: 208.2887\n",
      "Epoch 710/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.5313 - val_loss: 208.8286\n",
      "Epoch 711/1000\n",
      "1500/1500 [==============================] - 0s 143us/step - loss: 0.6649 - val_loss: 207.0980\n",
      "Epoch 712/1000\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 0.5685 - val_loss: 207.3763\n",
      "Epoch 713/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.4018 - val_loss: 207.6043\n",
      "Epoch 714/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 1.0352 - val_loss: 206.9651\n",
      "Epoch 715/1000\n",
      "1500/1500 [==============================] - 0s 146us/step - loss: 1.6983 - val_loss: 207.4394\n",
      "Epoch 716/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.9952 - val_loss: 206.3666\n",
      "Epoch 717/1000\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 0.6244 - val_loss: 208.4623\n",
      "Epoch 718/1000\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 0.4329 - val_loss: 207.9220\n",
      "Epoch 719/1000\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 0.5110 - val_loss: 207.8107\n",
      "Epoch 720/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.4840 - val_loss: 208.1910\n",
      "Epoch 721/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.4877 - val_loss: 208.4250\n",
      "Epoch 722/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.3808 - val_loss: 209.5445\n",
      "Epoch 723/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.7853 - val_loss: 209.4676\n",
      "Epoch 724/1000\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 0.8410 - val_loss: 207.5652\n",
      "Epoch 725/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.8271 - val_loss: 207.4580\n",
      "Epoch 726/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.7104 - val_loss: 208.3293\n",
      "Epoch 727/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 0.5481 - val_loss: 207.5333\n",
      "Epoch 728/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.2765 - val_loss: 207.3031\n",
      "Epoch 729/1000\n",
      "1500/1500 [==============================] - 0s 119us/step - loss: 0.3475 - val_loss: 207.4761\n",
      "Epoch 730/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 0.4688 - val_loss: 209.7905\n",
      "Epoch 731/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.5905 - val_loss: 207.8612\n",
      "Epoch 732/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.3754 - val_loss: 207.3620\n",
      "Epoch 733/1000\n",
      "1500/1500 [==============================] - 0s 119us/step - loss: 0.2320 - val_loss: 206.6430\n",
      "Epoch 734/1000\n",
      "1500/1500 [==============================] - 0s 123us/step - loss: 0.6415 - val_loss: 207.2414\n",
      "Epoch 735/1000\n",
      "1500/1500 [==============================] - 0s 125us/step - loss: 0.8926 - val_loss: 208.9035\n",
      "Epoch 736/1000\n",
      "1500/1500 [==============================] - 0s 128us/step - loss: 5.1175 - val_loss: 211.2785\n",
      "Epoch 737/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 5.5575 - val_loss: 207.0138\n",
      "Epoch 738/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 2.7021 - val_loss: 206.2007\n",
      "Epoch 739/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 1.1907 - val_loss: 207.4581\n",
      "Epoch 740/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.7007 - val_loss: 205.8757\n",
      "Epoch 741/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 0.3438 - val_loss: 206.5743\n",
      "Epoch 742/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.3347 - val_loss: 206.8657\n",
      "Epoch 743/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.1409 - val_loss: 206.5516\n",
      "Epoch 744/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.1487 - val_loss: 207.2493\n",
      "Epoch 745/1000\n",
      "1500/1500 [==============================] - 0s 81us/step - loss: 0.1297 - val_loss: 207.5139\n",
      "Epoch 746/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.1468 - val_loss: 207.7247\n",
      "Epoch 747/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.0761 - val_loss: 207.3543\n",
      "Epoch 748/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 0.2422 - val_loss: 205.8005\n",
      "Epoch 749/1000\n",
      "1500/1500 [==============================] - 0s 115us/step - loss: 0.4088 - val_loss: 207.8092\n",
      "Epoch 750/1000\n",
      "1500/1500 [==============================] - 0s 116us/step - loss: 0.2520 - val_loss: 207.0508\n",
      "Epoch 751/1000\n",
      "1500/1500 [==============================] - 0s 117us/step - loss: 0.2757 - val_loss: 208.3792\n",
      "Epoch 752/1000\n",
      "1500/1500 [==============================] - 0s 117us/step - loss: 0.4884 - val_loss: 208.1001\n",
      "Epoch 753/1000\n",
      "1500/1500 [==============================] - 0s 120us/step - loss: 0.4680 - val_loss: 207.2048\n",
      "Epoch 754/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.2456 - val_loss: 207.6814\n",
      "Epoch 755/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.1683 - val_loss: 206.7196\n",
      "Epoch 756/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.1299 - val_loss: 206.9525\n",
      "Epoch 757/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.1145 - val_loss: 207.4807\n",
      "Epoch 758/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.1348 - val_loss: 207.1485\n",
      "Epoch 759/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.1339 - val_loss: 207.5506\n",
      "Epoch 760/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.0838 - val_loss: 207.3395\n",
      "Epoch 761/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.1829 - val_loss: 208.0705\n",
      "Epoch 762/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.2843 - val_loss: 207.4276\n",
      "Epoch 763/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.2958 - val_loss: 206.7028\n",
      "Epoch 764/1000\n",
      "1500/1500 [==============================] - 0s 146us/step - loss: 1.3462 - val_loss: 210.1503\n",
      "Epoch 765/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 1.9899 - val_loss: 209.4571\n",
      "Epoch 766/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 1.8584 - val_loss: 207.0856\n",
      "Epoch 767/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 1.6081 - val_loss: 208.3299\n",
      "Epoch 768/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 1.2918 - val_loss: 205.8047\n",
      "Epoch 769/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.6812 - val_loss: 208.2784\n",
      "Epoch 770/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.3782 - val_loss: 206.6925\n",
      "Epoch 771/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.3273 - val_loss: 206.7267\n",
      "Epoch 772/1000\n",
      "1500/1500 [==============================] - 0s 146us/step - loss: 0.2852 - val_loss: 207.0737\n",
      "Epoch 773/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.2297 - val_loss: 206.6462\n",
      "Epoch 774/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.1768 - val_loss: 206.8549\n",
      "Epoch 775/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 0.2601 - val_loss: 207.9829\n",
      "Epoch 776/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.3727 - val_loss: 207.4663\n",
      "Epoch 777/1000\n",
      "1500/1500 [==============================] - 0s 146us/step - loss: 0.5231 - val_loss: 210.6985\n",
      "Epoch 778/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 2.8322 - val_loss: 206.8584\n",
      "Epoch 779/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 2.4455 - val_loss: 206.1233\n",
      "Epoch 780/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 1.6260 - val_loss: 207.2139\n",
      "Epoch 781/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 1.8411 - val_loss: 204.4320\n",
      "Epoch 782/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.9863 - val_loss: 205.6417\n",
      "Epoch 783/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.4254 - val_loss: 207.0052\n",
      "Epoch 784/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 0.4638 - val_loss: 207.3347\n",
      "Epoch 785/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 0.2398 - val_loss: 206.6044\n",
      "Epoch 786/1000\n",
      "1500/1500 [==============================] - 0s 155us/step - loss: 0.1284 - val_loss: 206.9102\n",
      "Epoch 787/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.1096 - val_loss: 207.0867\n",
      "Epoch 788/1000\n",
      "1500/1500 [==============================] - 0s 156us/step - loss: 0.0825 - val_loss: 207.1199\n",
      "Epoch 789/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.1344 - val_loss: 207.7217\n",
      "Epoch 790/1000\n",
      "1500/1500 [==============================] - 0s 154us/step - loss: 0.2160 - val_loss: 206.6624\n",
      "Epoch 791/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.1058 - val_loss: 207.5105\n",
      "Epoch 792/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.2129 - val_loss: 207.3470\n",
      "Epoch 793/1000\n",
      "1500/1500 [==============================] - 0s 117us/step - loss: 0.1925 - val_loss: 207.3623\n",
      "Epoch 794/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 0.7190 - val_loss: 205.9334\n",
      "Epoch 795/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 1.1327 - val_loss: 207.8956\n",
      "Epoch 796/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.9883 - val_loss: 207.7627\n",
      "Epoch 797/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 3.1008 - val_loss: 209.8651\n",
      "Epoch 798/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 9.0357 - val_loss: 208.9291\n",
      "Epoch 799/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 4.9921 - val_loss: 205.2792\n",
      "Epoch 800/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 1.7929 - val_loss: 204.9953\n",
      "Epoch 801/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 0.9195 - val_loss: 207.3218\n",
      "Epoch 802/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 1.1154 - val_loss: 208.8804\n",
      "Epoch 803/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 1.1253 - val_loss: 205.9025\n",
      "Epoch 804/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 0.3205 - val_loss: 206.5680\n",
      "Epoch 805/1000\n",
      "1500/1500 [==============================] - 0s 116us/step - loss: 0.3054 - val_loss: 206.6597\n",
      "Epoch 806/1000\n",
      "1500/1500 [==============================] - 0s 115us/step - loss: 0.3065 - val_loss: 207.9928\n",
      "Epoch 807/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.1548 - val_loss: 206.4560\n",
      "Epoch 808/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.1109 - val_loss: 206.5065\n",
      "Epoch 809/1000\n",
      "1500/1500 [==============================] - 0s 129us/step - loss: 0.0926 - val_loss: 206.5979\n",
      "Epoch 810/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.0859 - val_loss: 207.1197\n",
      "Epoch 811/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 0.0807 - val_loss: 206.7843\n",
      "Epoch 812/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 0.0746 - val_loss: 206.5085\n",
      "Epoch 813/1000\n",
      "1500/1500 [==============================] - 0s 78us/step - loss: 0.0433 - val_loss: 206.8685\n",
      "Epoch 814/1000\n",
      "1500/1500 [==============================] - 0s 82us/step - loss: 0.0323 - val_loss: 206.7924\n",
      "Epoch 815/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.0319 - val_loss: 206.6249\n",
      "Epoch 816/1000\n",
      "1500/1500 [==============================] - 0s 113us/step - loss: 0.0320 - val_loss: 206.9138\n",
      "Epoch 817/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 0.0237 - val_loss: 206.8650\n",
      "Epoch 818/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 134us/step - loss: 0.0202 - val_loss: 206.9367\n",
      "Epoch 819/1000\n",
      "1500/1500 [==============================] - 0s 130us/step - loss: 0.0180 - val_loss: 206.9705\n",
      "Epoch 820/1000\n",
      "1500/1500 [==============================] - 0s 144us/step - loss: 0.0154 - val_loss: 206.7859\n",
      "Epoch 821/1000\n",
      "1500/1500 [==============================] - 0s 149us/step - loss: 0.0239 - val_loss: 206.9121\n",
      "Epoch 822/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.0267 - val_loss: 207.5120\n",
      "Epoch 823/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.0608 - val_loss: 206.9108\n",
      "Epoch 824/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.0662 - val_loss: 207.1966\n",
      "Epoch 825/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.0855 - val_loss: 207.8463\n",
      "Epoch 826/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.2427 - val_loss: 206.4134\n",
      "Epoch 827/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.3247 - val_loss: 206.6053\n",
      "Epoch 828/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 0.3874 - val_loss: 207.0426\n",
      "Epoch 829/1000\n",
      "1500/1500 [==============================] - 0s 147us/step - loss: 1.3280 - val_loss: 213.7382\n",
      "Epoch 830/1000\n",
      "1500/1500 [==============================] - 0s 150us/step - loss: 8.5730 - val_loss: 211.6566\n",
      "Epoch 831/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 4.3733 - val_loss: 208.3181\n",
      "Epoch 832/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 3.0621 - val_loss: 208.4734\n",
      "Epoch 833/1000\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 1.3556 - val_loss: 205.0941\n",
      "Epoch 834/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.5092 - val_loss: 205.9504\n",
      "Epoch 835/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 0.2790 - val_loss: 204.4854\n",
      "Epoch 836/1000\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 0.1648 - val_loss: 204.5798\n",
      "Epoch 837/1000\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 0.2782 - val_loss: 204.6414\n",
      "Epoch 838/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 0.1723 - val_loss: 205.3362\n",
      "Epoch 839/1000\n",
      "1500/1500 [==============================] - 0s 119us/step - loss: 0.1414 - val_loss: 205.8166\n",
      "Epoch 840/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.0969 - val_loss: 204.5441\n",
      "Epoch 841/1000\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 0.2947 - val_loss: 207.4147\n",
      "Epoch 842/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.7201 - val_loss: 205.2783\n",
      "Epoch 843/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.3422 - val_loss: 205.6539\n",
      "Epoch 844/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.2679 - val_loss: 204.7025\n",
      "Epoch 845/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.2101 - val_loss: 205.1003\n",
      "Epoch 846/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.0827 - val_loss: 205.5493\n",
      "Epoch 847/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.0490 - val_loss: 205.4501\n",
      "Epoch 848/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.0485 - val_loss: 205.2429\n",
      "Epoch 849/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.0407 - val_loss: 205.3778\n",
      "Epoch 850/1000\n",
      "1500/1500 [==============================] - 0s 107us/step - loss: 0.0433 - val_loss: 205.3927\n",
      "Epoch 851/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.0445 - val_loss: 205.1383\n",
      "Epoch 852/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 0.0561 - val_loss: 205.0534\n",
      "Epoch 853/1000\n",
      "1500/1500 [==============================] - 0s 95us/step - loss: 0.0505 - val_loss: 205.3885\n",
      "Epoch 854/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.0367 - val_loss: 204.9779\n",
      "Epoch 855/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.0267 - val_loss: 205.2769\n",
      "Epoch 856/1000\n",
      "1500/1500 [==============================] - 0s 93us/step - loss: 0.0436 - val_loss: 205.3749\n",
      "Epoch 857/1000\n",
      "1500/1500 [==============================] - 0s 91us/step - loss: 0.5221 - val_loss: 204.8163\n",
      "Epoch 858/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 1.4018 - val_loss: 205.7626\n",
      "Epoch 859/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 1.1052 - val_loss: 205.0634\n",
      "Epoch 860/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.7838 - val_loss: 205.3077\n",
      "Epoch 861/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 2.3834 - val_loss: 211.0124\n",
      "Epoch 862/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 5.8586 - val_loss: 210.4384\n",
      "Epoch 863/1000\n",
      "1500/1500 [==============================] - 0s 85us/step - loss: 5.6566 - val_loss: 218.2929\n",
      "Epoch 864/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 2.4377 - val_loss: 205.9122\n",
      "Epoch 865/1000\n",
      "1500/1500 [==============================] - 0s 88us/step - loss: 0.8530 - val_loss: 205.2237\n",
      "Epoch 866/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 0.3796 - val_loss: 205.7057\n",
      "Epoch 867/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 0.3298 - val_loss: 204.7475\n",
      "Epoch 868/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.1743 - val_loss: 204.6822\n",
      "Epoch 869/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.1653 - val_loss: 204.3719\n",
      "Epoch 870/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.1457 - val_loss: 205.0944\n",
      "Epoch 871/1000\n",
      "1500/1500 [==============================] - 0s 97us/step - loss: 0.2118 - val_loss: 204.4089\n",
      "Epoch 872/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.1198 - val_loss: 204.5103\n",
      "Epoch 873/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 0.1066 - val_loss: 204.6780\n",
      "Epoch 874/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 0.1285 - val_loss: 204.7588\n",
      "Epoch 875/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 0.0995 - val_loss: 204.9936\n",
      "Epoch 876/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 0.0553 - val_loss: 204.6027\n",
      "Epoch 877/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 0.0471 - val_loss: 205.3465\n",
      "Epoch 878/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 0.0302 - val_loss: 204.6286\n",
      "Epoch 879/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 0.0239 - val_loss: 204.6520\n",
      "Epoch 880/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 0.0301 - val_loss: 204.4439\n",
      "Epoch 881/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 0.0183 - val_loss: 204.5011\n",
      "Epoch 882/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 0.0144 - val_loss: 204.3120\n",
      "Epoch 883/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 0.0165 - val_loss: 204.5412\n",
      "Epoch 884/1000\n",
      "1500/1500 [==============================] - 0s 107us/step - loss: 0.0174 - val_loss: 204.6668\n",
      "Epoch 885/1000\n",
      "1500/1500 [==============================] - 0s 110us/step - loss: 0.0206 - val_loss: 204.6724\n",
      "Epoch 886/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 0.0331 - val_loss: 204.6227\n",
      "Epoch 887/1000\n",
      "1500/1500 [==============================] - 0s 110us/step - loss: 0.0555 - val_loss: 204.6245\n",
      "Epoch 888/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 0.0854 - val_loss: 205.6857\n",
      "Epoch 889/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 0.6237 - val_loss: 205.1113\n",
      "Epoch 890/1000\n",
      "1500/1500 [==============================] - 0s 109us/step - loss: 0.5210 - val_loss: 206.4176\n",
      "Epoch 891/1000\n",
      "1500/1500 [==============================] - 0s 109us/step - loss: 0.3934 - val_loss: 205.5151\n",
      "Epoch 892/1000\n",
      "1500/1500 [==============================] - 0s 110us/step - loss: 0.6089 - val_loss: 205.5981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 893/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 2.3963 - val_loss: 203.1309\n",
      "Epoch 894/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 2.3883 - val_loss: 206.3353\n",
      "Epoch 895/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 0.8018 - val_loss: 204.5102\n",
      "Epoch 896/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.7072 - val_loss: 204.1521\n",
      "Epoch 897/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.7200 - val_loss: 204.4683\n",
      "Epoch 898/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.8016 - val_loss: 205.2792\n",
      "Epoch 899/1000\n",
      "1500/1500 [==============================] - 0s 136us/step - loss: 0.3246 - val_loss: 205.3887\n",
      "Epoch 900/1000\n",
      "1500/1500 [==============================] - 0s 131us/step - loss: 0.4185 - val_loss: 204.5394\n",
      "Epoch 901/1000\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 0.8050 - val_loss: 204.6424\n",
      "Epoch 902/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.3850 - val_loss: 205.1566\n",
      "Epoch 903/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 0.3149 - val_loss: 203.6963\n",
      "Epoch 904/1000\n",
      "1500/1500 [==============================] - 0s 139us/step - loss: 0.2589 - val_loss: 205.9906\n",
      "Epoch 905/1000\n",
      "1500/1500 [==============================] - 0s 141us/step - loss: 0.5342 - val_loss: 204.5016\n",
      "Epoch 906/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 0.3751 - val_loss: 205.9005\n",
      "Epoch 907/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 0.2668 - val_loss: 205.3738\n",
      "Epoch 908/1000\n",
      "1500/1500 [==============================] - 0s 134us/step - loss: 0.2731 - val_loss: 205.2963\n",
      "Epoch 909/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.4074 - val_loss: 204.3603\n",
      "Epoch 910/1000\n",
      "1500/1500 [==============================] - 0s 137us/step - loss: 0.7774 - val_loss: 205.9041\n",
      "Epoch 911/1000\n",
      "1500/1500 [==============================] - 0s 138us/step - loss: 1.8140 - val_loss: 204.1009\n",
      "Epoch 912/1000\n",
      "1500/1500 [==============================] - 0s 132us/step - loss: 1.7360 - val_loss: 206.5203\n",
      "Epoch 913/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 1.6007 - val_loss: 207.2423\n",
      "Epoch 914/1000\n",
      "1500/1500 [==============================] - 0s 135us/step - loss: 0.7386 - val_loss: 208.5266\n",
      "Epoch 915/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 0.3742 - val_loss: 206.3446\n",
      "Epoch 916/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.3652 - val_loss: 204.1322\n",
      "Epoch 917/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 0.5429 - val_loss: 205.4686\n",
      "Epoch 918/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.6907 - val_loss: 203.9091\n",
      "Epoch 919/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 0.3335 - val_loss: 205.1582\n",
      "Epoch 920/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 0.4695 - val_loss: 203.6061\n",
      "Epoch 921/1000\n",
      "1500/1500 [==============================] - 0s 115us/step - loss: 0.4799 - val_loss: 206.7429\n",
      "Epoch 922/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 0.6002 - val_loss: 204.1789\n",
      "Epoch 923/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 0.3121 - val_loss: 205.3029\n",
      "Epoch 924/1000\n",
      "1500/1500 [==============================] - 0s 109us/step - loss: 0.7032 - val_loss: 204.8367\n",
      "Epoch 925/1000\n",
      "1500/1500 [==============================] - 0s 109us/step - loss: 0.4492 - val_loss: 205.1895\n",
      "Epoch 926/1000\n",
      "1500/1500 [==============================] - 0s 114us/step - loss: 0.5186 - val_loss: 204.3165\n",
      "Epoch 927/1000\n",
      "1500/1500 [==============================] - 0s 111us/step - loss: 0.4995 - val_loss: 204.9344\n",
      "Epoch 928/1000\n",
      "1500/1500 [==============================] - 0s 110us/step - loss: 0.4820 - val_loss: 203.0054\n",
      "Epoch 929/1000\n",
      "1500/1500 [==============================] - 0s 111us/step - loss: 0.7434 - val_loss: 205.8847\n",
      "Epoch 930/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 0.6634 - val_loss: 204.4365\n",
      "Epoch 931/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 0.4434 - val_loss: 204.1654\n",
      "Epoch 932/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 0.4992 - val_loss: 204.6277\n",
      "Epoch 933/1000\n",
      "1500/1500 [==============================] - 0s 106us/step - loss: 0.4947 - val_loss: 205.0620\n",
      "Epoch 934/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 0.2656 - val_loss: 204.9143\n",
      "Epoch 935/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 0.1691 - val_loss: 204.8561\n",
      "Epoch 936/1000\n",
      "1500/1500 [==============================] - 0s 104us/step - loss: 0.9039 - val_loss: 206.2792\n",
      "Epoch 937/1000\n",
      "1500/1500 [==============================] - 0s 108us/step - loss: 0.9721 - val_loss: 203.7555\n",
      "Epoch 938/1000\n",
      "1500/1500 [==============================] - 0s 114us/step - loss: 0.7547 - val_loss: 203.2744\n",
      "Epoch 939/1000\n",
      "1500/1500 [==============================] - 0s 111us/step - loss: 0.9145 - val_loss: 204.2065\n",
      "Epoch 940/1000\n",
      "1500/1500 [==============================] - 0s 115us/step - loss: 0.6691 - val_loss: 204.2528\n",
      "Epoch 941/1000\n",
      "1500/1500 [==============================] - 0s 116us/step - loss: 0.6538 - val_loss: 207.6617\n",
      "Epoch 942/1000\n",
      "1500/1500 [==============================] - 0s 114us/step - loss: 0.4967 - val_loss: 205.0298\n",
      "Epoch 943/1000\n",
      "1500/1500 [==============================] - 0s 115us/step - loss: 7.8247 - val_loss: 202.9751\n",
      "Epoch 944/1000\n",
      "1500/1500 [==============================] - 0s 114us/step - loss: 2.0575 - val_loss: 203.7099\n",
      "Epoch 945/1000\n",
      "1500/1500 [==============================] - 0s 114us/step - loss: 1.2144 - val_loss: 208.6055\n",
      "Epoch 946/1000\n",
      "1500/1500 [==============================] - 0s 113us/step - loss: 2.4589 - val_loss: 204.9377\n",
      "Epoch 947/1000\n",
      "1500/1500 [==============================] - 0s 114us/step - loss: 1.1775 - val_loss: 204.9713\n",
      "Epoch 948/1000\n",
      "1500/1500 [==============================] - 0s 116us/step - loss: 0.5506 - val_loss: 205.4723\n",
      "Epoch 949/1000\n",
      "1500/1500 [==============================] - 0s 113us/step - loss: 0.3140 - val_loss: 208.1203\n",
      "Epoch 950/1000\n",
      "1500/1500 [==============================] - 0s 116us/step - loss: 0.5437 - val_loss: 206.2726\n",
      "Epoch 951/1000\n",
      "1500/1500 [==============================] - 0s 116us/step - loss: 0.4366 - val_loss: 204.5349\n",
      "Epoch 952/1000\n",
      "1500/1500 [==============================] - 0s 115us/step - loss: 0.2089 - val_loss: 203.5241\n",
      "Epoch 953/1000\n",
      "1500/1500 [==============================] - 0s 116us/step - loss: 0.1672 - val_loss: 205.3187\n",
      "Epoch 954/1000\n",
      "1500/1500 [==============================] - 0s 116us/step - loss: 0.1222 - val_loss: 204.5243\n",
      "Epoch 955/1000\n",
      "1500/1500 [==============================] - 0s 117us/step - loss: 0.0503 - val_loss: 204.6664\n",
      "Epoch 956/1000\n",
      "1500/1500 [==============================] - 0s 121us/step - loss: 0.0515 - val_loss: 204.5911\n",
      "Epoch 957/1000\n",
      "1500/1500 [==============================] - 0s 113us/step - loss: 0.0382 - val_loss: 204.4380\n",
      "Epoch 958/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.0776 - val_loss: 204.3576\n",
      "Epoch 959/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.0454 - val_loss: 204.5921\n",
      "Epoch 960/1000\n",
      "1500/1500 [==============================] - 0s 89us/step - loss: 0.0465 - val_loss: 204.8379\n",
      "Epoch 961/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.0517 - val_loss: 204.2536\n",
      "Epoch 962/1000\n",
      "1500/1500 [==============================] - 0s 87us/step - loss: 0.0491 - val_loss: 204.2450\n",
      "Epoch 963/1000\n",
      "1500/1500 [==============================] - 0s 83us/step - loss: 0.1329 - val_loss: 204.8437\n",
      "Epoch 964/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 0.2305 - val_loss: 203.7008\n",
      "Epoch 965/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.1616 - val_loss: 204.9496\n",
      "Epoch 966/1000\n",
      "1500/1500 [==============================] - 0s 90us/step - loss: 0.3394 - val_loss: 204.5316\n",
      "Epoch 967/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 92us/step - loss: 0.4949 - val_loss: 206.4899\n",
      "Epoch 968/1000\n",
      "1500/1500 [==============================] - 0s 100us/step - loss: 0.7915 - val_loss: 203.1379\n",
      "Epoch 969/1000\n",
      "1500/1500 [==============================] - 0s 103us/step - loss: 3.4753 - val_loss: 202.7696\n",
      "Epoch 970/1000\n",
      "1500/1500 [==============================] - 0s 101us/step - loss: 5.7176 - val_loss: 206.1583\n",
      "Epoch 971/1000\n",
      "1500/1500 [==============================] - 0s 98us/step - loss: 1.3157 - val_loss: 204.1567\n",
      "Epoch 972/1000\n",
      "1500/1500 [==============================] - 0s 99us/step - loss: 1.0786 - val_loss: 204.8728\n",
      "Epoch 973/1000\n",
      "1500/1500 [==============================] - 0s 107us/step - loss: 0.4050 - val_loss: 204.4617\n",
      "Epoch 974/1000\n",
      "1500/1500 [==============================] - 0s 133us/step - loss: 0.5601 - val_loss: 206.7209\n",
      "Epoch 975/1000\n",
      "1500/1500 [==============================] - 0s 145us/step - loss: 1.2166 - val_loss: 205.9192\n",
      "Epoch 976/1000\n",
      "1500/1500 [==============================] - 0s 151us/step - loss: 0.6135 - val_loss: 204.8265\n",
      "Epoch 977/1000\n",
      "1500/1500 [==============================] - 0s 160us/step - loss: 0.2322 - val_loss: 204.7939\n",
      "Epoch 978/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.1334 - val_loss: 204.6449\n",
      "Epoch 979/1000\n",
      "1500/1500 [==============================] - 0s 152us/step - loss: 0.0773 - val_loss: 204.2817\n",
      "Epoch 980/1000\n",
      "1500/1500 [==============================] - 0s 153us/step - loss: 0.0583 - val_loss: 204.5755\n",
      "Epoch 981/1000\n",
      "1500/1500 [==============================] - 0s 158us/step - loss: 0.0601 - val_loss: 204.5359\n",
      "Epoch 982/1000\n",
      "1500/1500 [==============================] - 0s 148us/step - loss: 0.0724 - val_loss: 203.8988\n",
      "Epoch 983/1000\n",
      "1500/1500 [==============================] - 0s 94us/step - loss: 0.0668 - val_loss: 204.4083\n",
      "Epoch 984/1000\n",
      "1500/1500 [==============================] - 0s 86us/step - loss: 0.0592 - val_loss: 204.3072\n",
      "Epoch 985/1000\n",
      "1500/1500 [==============================] - 0s 92us/step - loss: 0.0452 - val_loss: 204.3142\n",
      "Epoch 986/1000\n",
      "1500/1500 [==============================] - 0s 105us/step - loss: 0.0765 - val_loss: 203.9944\n",
      "Epoch 987/1000\n",
      "1500/1500 [==============================] - 0s 107us/step - loss: 0.0972 - val_loss: 203.9489\n",
      "Epoch 988/1000\n",
      "1500/1500 [==============================] - 0s 117us/step - loss: 0.0767 - val_loss: 203.7379\n",
      "Epoch 989/1000\n",
      "1500/1500 [==============================] - 0s 114us/step - loss: 0.0620 - val_loss: 204.4464\n",
      "Epoch 990/1000\n",
      "1500/1500 [==============================] - 0s 116us/step - loss: 0.6861 - val_loss: 204.6381\n",
      "Epoch 991/1000\n",
      "1500/1500 [==============================] - 0s 113us/step - loss: 0.5074 - val_loss: 204.0945\n",
      "Epoch 992/1000\n",
      "1500/1500 [==============================] - 0s 113us/step - loss: 0.4747 - val_loss: 203.3199\n",
      "Epoch 993/1000\n",
      "1500/1500 [==============================] - 0s 119us/step - loss: 0.4932 - val_loss: 205.1192\n",
      "Epoch 994/1000\n",
      "1500/1500 [==============================] - 0s 116us/step - loss: 0.4457 - val_loss: 208.2385\n",
      "Epoch 995/1000\n",
      "1500/1500 [==============================] - 0s 114us/step - loss: 1.4884 - val_loss: 204.7364\n",
      "Epoch 996/1000\n",
      "1500/1500 [==============================] - 0s 116us/step - loss: 0.7163 - val_loss: 203.9336\n",
      "Epoch 997/1000\n",
      "1500/1500 [==============================] - 0s 116us/step - loss: 0.4897 - val_loss: 205.1129\n",
      "Epoch 998/1000\n",
      "1500/1500 [==============================] - 0s 119us/step - loss: 0.2570 - val_loss: 204.6026\n",
      "Epoch 999/1000\n",
      "1500/1500 [==============================] - 0s 112us/step - loss: 0.7205 - val_loss: 204.1032\n",
      "Epoch 1000/1000\n",
      "1500/1500 [==============================] - 0s 84us/step - loss: 0.8171 - val_loss: 204.0592\n"
     ]
    }
   ],
   "source": [
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 3. 모델 학습과정 설정하기\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "hist = model.fit(x_train, y_train, batch_size=32, epochs=1000, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. 학습과정 살펴보기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.ylim(0.0, 300.0)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 321us/step\n",
      "179.5131970214844\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 6. 모델 평가하기\n",
    "score = model.evaluate(x_test, y_test, batch_size=32)\n",
    "\n",
    "print(score)\n",
    "\n",
    "# 7. 모델 사용하기\n",
    "yhat_test = model.predict(x_test, batch_size=32)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt_row = 5\n",
    "plt_col = 5\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "f, axarr = plt.subplots(plt_row, plt_col)\n",
    "\n",
    "for i in range(plt_row*plt_col):\n",
    "    sub_plt = axarr[i//plt_row, i%plt_col]\n",
    "    sub_plt.axis('off')\n",
    "    sub_plt.imshow(x_test[i].reshape(width, height))\n",
    "    sub_plt.set_title('R %d P %.1f' % (y_test[i][0], yhat_test[i][0]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
